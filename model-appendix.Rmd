---
title: "Appendix: model results and supplementary plots"
author: "Gigi Lovicu and Ivan Aguilar"
date: "20/12/2021"
output: html_document
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
source(paste0('/home/gigilovicu/Documents/masters/semester_1/statistics/project_submission/code/stats_project_data.R'))
``` 

```{r theme, include = FALSE}
our_theme <- theme_classic() +
             theme(axis.line = element_line(color='black'),
                          plot.background = element_blank(),
                          plot.caption = element_text(hjust = 0),
                          panel.grid.major = element_blank(),
                          panel.grid.minor = element_blank(),
                          panel.border = element_blank())

```

The theoretical r2 graph allows us to perform prior elicitation on our g selection for our BMS model.
Setting g with this prior elicitation ensures that it encodes prior beliefs that are minimally sensible. Our selected value is g = 0.01

```{r prior_elicitation, echo = FALSE}
#Match in tibble with values of g
r2_tibble <- tibble(g_grid, r2)
# Plot theoretical R2
plot_theoretical_r2 <- ggplot(r2_tibble, aes(x = g_grid, y = r2)) +
                       geom_line() +
                       ylab('R-squared') +
                       xlab("Possible g values") +
                       geom_hline(yintercept = 0.5, col = 'red', size = 0.8) +
                       scale_y_continuous(c(0, 1)) +
                       xlim(c(0,1)) +
                       ggtitle(expression(paste('Theoretical ',R^2, ' (wide data)')))

plot_theoretical_r2
```
We run a full set of diagnostics for our BMS model to assess convergence. We ran 5000 iterations and in summary we see no evidence that the chain didn't converge. 
The marginal inclusion probabilities graph shows in red the estimates with >.90 posterior probability (top left).
The precision on the posterior inclusion probabilities at each iteration looks stable from 2000 iterations onward (top right).
Model size and log posterior model probability also stabilizes nicely throughout the full diagnostics (bottom)

```{r BMS_diagnostics, echo = FALSE}
#Trace of the number of variables at each MCMC iteration.
season_var_per_iter <- tibble(iteration = 1:nrow(season_bayes$postSample),
                              nvars= rowSums(season_bayes$postSample))

plot_vars_per_iter <- ggplot(season_var_per_iter, aes(x = iteration, y = nvars)) +
                      geom_line() +
                      xlab("Iteration number") +
                      ylab("Variables included") +
                      ggtitle("Model size", subtitle = "By iteration, MCMC with Gibbs Sampling")
  
#Log posterior model probabilities
season_log_post_prob_iter <- tibble(iteration = 1:length(season_bayes$postProb),
                                    prob = season_bayes$postProb)

plot_postprob_iter <- ggplot(season_log_post_prob_iter, aes(x = iteration, y = prob)) +
                      geom_line() +
                      xlab("Iteration number") +
                      ggtitle("Log Posterior Model Probability", subtitle = "By iteration, MCMC with Gibbs Sampling")

#Marginal posterior inclusion probabilities
prob_var_inc <-  matrix(NA, nrow= nrow(season_bayes$postSample), ncol = ncol(season_bayes$postSample))
for(j in 1:(ncol(season_bayes$postSample))) {
  prob_var_inc[, j]= cumsum(season_bayes$postSample[, j])/(1:nrow(season_bayes$postSample))
}

#Inclusion probabilities at last iteration
coef_final_iter <- tibble(variable = names(coef(season_bayes)[-c(1,nrow(coef(season_bayes))),'margpp']),
                          coefficient = coef(season_bayes)[-c(1,nrow(coef(season_bayes))),'margpp'])

coef_high_prob <- coef_final_iter %>% mutate(color = if_else(coefficient >= 0.9, 'red', 'grey'))

prob_var_inc <- tibble(iter = 1:nrow(season_bayes$postSample), prob_var_inc %>% data.frame() %>%
                       `colnames<-`(coef_high_prob$variable)) %>% 
                pivot_longer(-iter, names_to = "variable") %>% arrange(variable) %>%
                left_join(coef_high_prob %>% dplyr::select(variable, color), by = 'variable')

plot_prob_var_iter <- ggplot(prob_var_inc, aes(x = iter, y = value, group = variable)) +
                      geom_line(color = prob_var_inc$color) +
                      xlab('Iteration') +
                      ylab("probability") +
                      ggtitle("Posterior Marginal Inclusion Probability", subtitle = "By Iteration, MCMC with Gibbs Sampling\n(each line is a variable)")

plot_coef_final_iter <- ggplot(coef_final_iter, aes(x = variable, y = coefficient)) +
                        geom_point(size = 1, alpha = 0.8, color = coef_high_prob$color) +
                        xlab('variable') +
                        ylab("probability") +
                        scale_x_discrete() +
                        theme(axis.text.x=element_blank(),
                              axis.ticks.x=element_blank()) +
                        ggtitle("Posterior Marginal Inclusion Probability",
                                subtitle = "Final Iteration, MCMC with Gibbs Sampling")

#Model selection diagnostics - arrange plots
model_selection_plots <- plot_grid(plot_coef_final_iter, plot_prob_var_iter, plot_vars_per_iter,
                                   plot_postprob_iter, ncol = 2, nrow = 2)

model_selection_plots

```
In the graphics below we see the full list of coefficients for our player data (wide data) for the following models:

- Lasso: marked in red are the statistically significant coefficients at 10% or below
- BMS: marked in red are the coefficients with a marginal posterior probability greater than 0.9 

In the main body of our study we normally only review the significant coefficients for these models, so here we post the full list for informative purposes. 

```{r reg_comparison_appendix, echo = FALSE}
chart_data_lasso_full <- season_lasso %>% data.frame() %>%
                         mutate(variable = rownames(season_lasso)) %>% 
                         tibble() %>% mutate(color = if_else(pvalue < 0.1, 'red', 'grey')) %>% 
                         arrange(desc(estimate))

plot_credintervals_lasso <- ggplot(chart_data_lasso_full, aes(x = variable,
                                                              y = estimate)) +
                            geom_errorbar(aes(ymin = ci.low, ymax = ci.up), 
                                          lwd = 0.2,
                                          color = chart_data_lasso_full$color, width = 0) +
                            geom_point(size = 0.8, pch = 21, fill= "black", alpha = 0.8) +
                            scale_x_discrete(breaks = chart_data_lasso_full$variable) +
                            ggtitle("Season Wins versus Player Metrics",
                                    subtitle = "L1 penalisation, intervals calculated using post inference method from Lee et al (2016)") +
                            labs(caption = "Red variables are statistically significant (at 10% level or below)") +
                            our_theme +
                            theme(axis.text=element_text(size=6,angle=90))

#bayesian
chart_data_bayes_long <- season_bayes_full %>%
                         mutate(color = if_else(margpp > 0.9, 'red', 'grey')) %>%
                         filter(variable != 'intercept')
                              
plot_credintervals_bayes <- ggplot(chart_data_bayes_long, aes(x = variable, y = estimate)) +
                            geom_errorbar(aes(ymin = X2.5., ymax = X97.5.), 
                                          lwd = 0.2,
                                          color = chart_data_bayes_long$color, width = 0) +
                            geom_point(size = 0.8, pch = 21, fill= "black", alpha = 0.8) +
                            scale_x_discrete(labels = chart_data_bayes_long$variable) +
                            ylab("coefficient") +                            
                            ggtitle("Season Wins versus Player Metrics",
                                    subtitle = "BMS") +
                            labs(caption = "Red variables have > 90% marginal posterior inclusion probability") +
                            our_theme +
                            theme(axis.text=element_text(size=6,angle=90))
                  
plot_credintervals_lasso
plot_credintervals_bayes
```

The full list of coefficients and resulting r-squared result for our OLS model on the team-level data (wide) is shown below.

```{r season_ols, echo = FALSE}
summary(season_ols)
```
Below we show the full list of coefficients and standard errors (calculated using the method in Lee et al (2016)) for our Lasso BIC model (with the optimal lambda) on the team-level data (wide).

```{r season_lasso, echo = FALSE}
season_lasso
```
In the table below we show all the coefficients estimates for our BMS model on the team-level data (wide).

```{r season_bayes, echo = FALSE}
season_bayes_full
```
We show here the top 10 BMS models with their posterior probabilities and selected features

```{r top_models, echo=FALSE}
head(postProb(season_bayes), 10)
```
The full list of coefficients and resulting r-squared result for our OLS model on the player-level data (long) is shown below.

```{r season_long_ols, echo = FALSE}
summary(season_long_ols)
```
The full list of coefficients for our quantile regression model on the player-level data (long) is shown below.

```{r season_long_qr, echo = FALSE}
summary(seasons_qr_median)
```
Full summary of the Nested Intercepts hierarchical model is shown below, including all the coefficient estimates for the team data (long)

```{r season_long_hm, echo = FALSE}
summary(season_hm)
```
Full summary of the Varying Intercepts and Varying Slope for Salary HHI hierarchical model is shown below, including all the coefficient estimates for the team data (long)

```{r season_long_hm2, echo = FALSE}
summary(season_hm_slope)
```
Below are the results of the ANOVA analysis, with tests for the inclusion of the random-effect terms in the model. The likelihood ratio tests show that the nested intercepts (team:season) should both be included.

```{r anova1, echo = FALSE}

rand(season_hm)
```

And here that the varying intercepts by season and varying salary_hhi slopes by team should both be included.

```{r anova2, echo = FALSE}
rand(season_hm_slope)
```
